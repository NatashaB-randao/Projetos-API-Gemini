{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"Sua Chave Aqui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-pro-exp-0827\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-exp-0827\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/gemini-exp-1114\n",
      "models/gemini-exp-1121\n"
     ]
    }
   ],
   "source": [
    "# Listar todos os modelos disponíveis na API e verificar quais suportam a geração de conteúdo\n",
    "\n",
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma instância do modelo generativo \"gemini-pro\"\n",
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicia um chat com o modelo, começando com um histórico vazio\n",
    "chat = model.start_chat(history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "# Bem Vindo(a) ao seu Assistente com Gemini AI #\n",
      "------------------------------------------------\n",
      "### Digite 'sair' para encerrar ###\n",
      "\n",
      "Gemini: Olá! É um prazer conhecê-lo. Sou Gemini, um modelo de linguagem de IA multimodal desenvolvido pelo Google. Como posso ajudá-lo hoje? \n",
      "\n",
      "Gemini: Olá! Como posso ajudá-lo hoje? Estou aqui para responder às suas perguntas e fornecer informações sobre uma ampla variedade de tópicos. \n",
      "\n",
      "Gemini: 1 \n",
      "\n",
      "Gemini: Sim, Al Pacino ganhou apenas um Oscar por sua atuação em \"Perfume de Mulher\" (1992). Ele foi indicado ao Oscar nove outras vezes, mas não ganhou. \n",
      "\n",
      "Gemini: É verdade, Al Pacino é um ator muito talentoso e respeitado, e muitos acreditam que ele merecia ter ganhado mais Oscars. No entanto, ele ganhou muitos outros prêmios por seu trabalho, incluindo dois Tony Awards, dois Emmy Awards e um BAFTA Award. \n",
      "\n",
      "Gemini: Obrigado por conversar comigo. Espero que tenha encontrado minhas respostas úteis. Até a próxima! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define uma mensagem de boas-vindas com formatação\n",
    "bem_vindo = \"# Bem Vindo(a) ao seu Assistente com Gemini AI #\"\n",
    "\n",
    "# Imprime uma linha que corresponde ao comprimento da mensagem de boas-vindas\n",
    "print(len(bem_vindo) * \"-\")\n",
    "\n",
    "print(bem_vindo)\n",
    "\n",
    "print(len(bem_vindo) * \"-\")\n",
    "\n",
    "# Informa ao usuário como encerrar o chat\n",
    "print(\"### Digite 'sair' para encerrar ###\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Inicia um loop que continuará até que o usuário decida sair\n",
    "while True:\n",
    "    texto = input(\"Escreva a sua mensagem: \")\n",
    "\n",
    "    if texto == \"sair\":\n",
    "        break\n",
    "\n",
    "    # Envia a mensagem do usuário para o modelo e armazena a resposta\n",
    "    response = chat.send_message(texto)\n",
    "\n",
    "    # Imprime a resposta do modelo\n",
    "    print(\"Gemini:\", response.text, \"\\n\")\n",
    "\n",
    "# Informa ao usuário que o chat está sendo encerrado\n",
    "print(\"Encerrando Chat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
